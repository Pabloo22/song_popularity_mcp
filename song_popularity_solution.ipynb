{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importamos las libreías necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported 0.2.03 version. Select nrows to a small number when running on huge datasets.\n",
      "output = featurewiz(dataname, target, corr_limit=0.90, verbose=2, sep=',', \n",
      "\t\theader=0, test_data='',feature_engg='', category_encoders='',\n",
      "\t\tdask_xgboost_flag=False, nrows=None, skip_sulov=False)\n",
      "Create new features via 'feature_engg' flag : ['interactions','groupby','target']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Libraries for data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Libraries for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pandas_profiling import ProfileReport  # py -3.9 -m pip install pandas-profiling\n",
    "\n",
    "# Libraries for machine learning\n",
    "from sklearn import (feature_selection, \n",
    "                    linear_model, \n",
    "                    model_selection, \n",
    "                    preprocessing,\n",
    "                    decomposition,\n",
    "                    metrics,\n",
    "                    impute,\n",
    "                    pipeline,\n",
    "                    compose,\n",
    "                    )\n",
    "\n",
    "# Feature engineering\n",
    "from featurewiz import featurewiz\n",
    "import feather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CREATE_REPORT = True  # Si ya se ha creado el reporte, no es necesario volver a crearlo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargamos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13184 entries, 0 to 13183\n",
      "Data columns (total 16 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   song_id           13184 non-null  Int64  \n",
      " 1   song_name         13184 non-null  string \n",
      " 2   song_popularity   13184 non-null  Int64  \n",
      " 3   song_duration_ms  13184 non-null  Int64  \n",
      " 4   acousticness      13184 non-null  Float64\n",
      " 5   danceability      13184 non-null  Float64\n",
      " 6   energy            13184 non-null  Float64\n",
      " 7   instrumentalness  13184 non-null  Float64\n",
      " 8   key               13184 non-null  Int64  \n",
      " 9   liveness          13184 non-null  Float64\n",
      " 10  loudness          13184 non-null  Float64\n",
      " 11  audio_mode        13184 non-null  Int64  \n",
      " 12  speechiness       13184 non-null  Float64\n",
      " 13  tempo             13184 non-null  Float64\n",
      " 14  time_signature    13184 non-null  Int64  \n",
      " 15  audio_valence     13184 non-null  Float64\n",
      "dtypes: Float64(9), Int64(6), string(1)\n",
      "memory usage: 1.8 MB\n"
     ]
    }
   ],
   "source": [
    "FILENAME = \"train\"\n",
    "df = pd.read_csv(f\"data/{FILENAME}.csv\")\n",
    "# Si una columna tiene menos de `threshold` valores únicos se considera categórica\n",
    "threshold = 1000\n",
    "df = df.apply(lambda x: x.astype(\"category\") if x.dtype == \"object\" and len(x.unique()) < threshold else x)\n",
    "df = df.convert_dtypes()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generamos el pandas-profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8053268a206a42b7a0b3f2d3bcf6e391"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fd7a44a150c44d7d8647aa0e54c02b9c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c26b4d61637d48f0b9f734987271037c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1a49c1db4fa4490ab68e6ecf6dbe28e3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if CREATE_REPORT:\n",
    "    profile = ProfileReport(df, infer_dtypes=False, progress_bar=True, minimal=False)\n",
    "    profile.to_file(f\"reports/{FILENAME}_report.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creamos una tabla con la información básica de cada variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crear una tabla con la información básica de cada variable nos permite hacernos una idea de cómo debemos tratar los datos para resolver el problema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La tabla contiene las siguientes columnas:\n",
    "* `variable`: nombre de la tabla de la que procede la columna.\n",
    "* `tipo`: tipo de la columna.\n",
    "* `max`: Si la columna es numérica, el valor máximo observado. Si es categórica se deja vacío.\n",
    "* `min`: Si la columna es numérica, el valor mínimo observado. Si es categórica se deja vacío.\n",
    "* `mean`: Si la columna es numérica, la media. Si es categórica, el valor más común.\n",
    "* `25%, 50%, 75%`: Los respectivos percentiles de las variables númericas.\n",
    "* `mode`: El valor que más se repite en cada columna.\n",
    "* `descripcion`: Descripción de la columna\n",
    "\n",
    "Con el siguiente programa creamos una primera versión del excel a la que luego se le podrá añadir información de manera manual (como los comentarios adicionales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = df.describe().T.drop(\"count\", axis=1).reset_index().rename(columns={\"index\": \"variable\"})\n",
    "most_repeated = df.mode().dropna().transpose().reset_index().rename({\"index\": \"variable\", 0: \"mode\"}, axis=1)\n",
    "base = base.merge(most_repeated, how='right', on='variable')\n",
    "# print(base.to_markdown())\n",
    "# base.to_csv(\"data/meta_info.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La tabla queda de la siguiente manera:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|    | variable         |           mean |          std |          min |          25% |            50% |            75% |             max | mode                |\n",
    "|---:|:-----------------|---------------:|-------------:|-------------:|-------------:|---------------:|---------------:|----------------:|:--------------------|\n",
    "|  0 | song_id          |   9397.54      |  5443.03     |     0        |   4690.75    |   9406         |  14090.5       | 18832           | 0                   |\n",
    "|  1 | song_name        |    nan         |   nan        |   nan        |    nan       |    nan         |    nan         |   nan           | Better              |\n",
    "|  2 | song_popularity  |     53.0719    |    21.7697   |     0        |     40       |     56         |     69         |   100           | 58                  |\n",
    "|  3 | song_duration_ms | 218514         | 60074.8      | 12000        | 184876       | 211794         | 243160         |     1.79935e+06 | 165000              |\n",
    "|  4 | acousticness     |      0.258629  |     0.288602 |     1.02e-06 |      0.0251  |      0.132     |      0.422     |     0.996       | 0.13                |\n",
    "|  5 | danceability     |      0.633784  |     0.155838 |     0        |      0.534   |      0.646     |      0.748     |     0.987       | 0.657               |\n",
    "|  6 | energy           |      0.64565   |     0.214098 |     0.00107  |      0.512   |      0.6745    |      0.816     |     0.997       | 0.7040000000000001  |\n",
    "|  7 | instrumentalness |      0.0770633 |     0.220458 |     0        |      0       |      1.085e-05 |      0.0025325 |     0.997       | 0.0                 |\n",
    "|  8 | key              |      5.26009   |     3.61606  |     0        |      2       |      5         |      8         |    11           | 1                   |\n",
    "|  9 | liveness         |      0.178801  |     0.143662 |     0.0109   |      0.0927  |      0.121     |      0.22      |     0.986       | 0.108               |\n",
    "| 10 | loudness         |     -7.44523   |     3.84463  |   -38.768    |     -9.03125 |     -6.5505    |     -4.897     |     1.585       | -5.9910000000000005 |\n",
    "| 11 | audio_mode       |      0.628186  |     0.483308 |     0        |      0       |      1         |      1         |     1           | 1                   |\n",
    "| 12 | speechiness      |      0.101205  |     0.10401  |     0        |      0.0378  |      0.0553    |      0.117     |     0.94        | 0.032               |\n",
    "| 13 | tempo            |    121.008     |    28.6638   |     0        |     98.8705  |    120.013     |    139.934     |   214.686       | 120.013             |\n",
    "| 14 | time_signature   |      3.96041   |     0.298589 |     0        |      4       |      4         |      4         |     5           | 4                   |\n",
    "| 15 | audio_valence    |      0.528415  |     0.246403 |     0        |      0.332   |      0.528     |      0.728     |     0.984       | 0.961  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que todas las características a excepción del nombre de la canción son númericas. Pasemos ahora a analizar cada una de ellas de manera más detallada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una de las observaciones adicionales que podemos hacer es que no hay valores nulos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis de correlaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes que nada realizamos un análisis preeliminar de correlaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_high_correlated_cols(df, threshold=0.95):\n",
    "    \"\"\"Returns a dict of highly correlated columns and the correlation from a dataframe.\"\"\"\n",
    "    corr_matrix = df.corr().abs()\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    high_correlated_columns_pairs_and_value = {}\n",
    "    for column in upper.columns:\n",
    "        for index in upper.index:\n",
    "            if upper.loc[index, column] > threshold:\n",
    "                high_correlated_columns_pairs_and_value[(column, index)] = upper.loc[index, column]\n",
    "    return high_correlated_columns_pairs_and_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En cuanto a la presencia de valores repetidos, podemos observar que la columna `time_signature` presenta más de un 94% de datos iguales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{('energy', 'acousticness'): 0.6604573163017611,\n ('loudness', 'acousticness'): 0.5602835002269761,\n ('loudness', 'energy'): 0.7597482191864439,\n ('loudness', 'instrumentalness'): 0.3891167411364504,\n ('audio_valence', 'danceability'): 0.3328347482231799,\n ('audio_valence', 'energy'): 0.31905923971135597}"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation = get_high_correlated_cols(df, threshold=0.3)\n",
    "correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analizando las correlaciones obtenidas podemos ver que las columnas `loudness` y `energy`, tal y como nos avisaba la descripción, se encuentran altamente correlacionadas. Por tanto, podemos prescendir de una de las dos ya que la información que aportan es muy similar. Hemos decidido quedarnos con las columna `energy` y descartar `loudness` debido a que por la descripción parece más interesante esta columna."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a hacer uso de la librería `featurewiz`. Esta librería nos permite crear de manera automática nuevas variables de las que luego se seleccionarán las mejores. \n",
    "\n",
    "Antes que nada vamos a eliminar las variables que no son númericas:\n",
    "* `song_id`: No aporta información al ser un identificador único\n",
    "* `song_name`: Esta variable se incluirá más adelante sustituyendo los valores por su frecuencia. No se realiza ahora esta sustitución para evitar el *data leakage*. Puesto que nuestra idea es realizar *cross validation*, si hiciesemos ahora esta conversión se estaría teniendo en cuenta los datos de validación a la hora de hacer la conversión.\n",
    "\n",
    "Las variables `loudness` y `energy` dejamos que las descarte el propio método de selección de características."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################################################################################\n",
      "############       F A S T   F E A T U R E  E N G G    A N D    S E L E C T I O N ! ########\n",
      "# Be judicious with featurewiz. Don't use it to create too many un-interpretable features! #\n",
      "############################################################################################\n",
      "Correlation Limit = 0.7\n",
      "Skipping feature engineering since no feature_engg input...\n",
      "Skipping category encoding since no category encoders specified in input...\n",
      "#### Single_Label Multi_Classification problem ####\n",
      "    Loaded train data. Shape = (13184, 14)\n",
      "#### Single_Label Multi_Classification problem ####\n",
      "No test data filename given...\n",
      "Classifying features using a random sample of 10000 rows from dataset...\n",
      "#### Single_Label Multi_Classification problem ####\n",
      "    loading a random sample of 10000 rows into pandas for EDA\n",
      "#######################################################################################\n",
      "######################## C L A S S I F Y I N G  V A R I A B L E S  ####################\n",
      "#######################################################################################\n",
      "song_duration_ms of type=Int64 is not classified\n",
      "acousticness of type=Float64 is not classified\n",
      "danceability of type=Float64 is not classified\n",
      "energy of type=Float64 is not classified\n",
      "instrumentalness of type=Float64 is not classified\n",
      "key of type=Int64 is not classified\n",
      "liveness of type=Float64 is not classified\n",
      "loudness of type=Float64 is not classified\n",
      "audio_mode of type=Int64 is not classified\n",
      "speechiness of type=Float64 is not classified\n",
      "tempo of type=Float64 is not classified\n",
      "time_signature of type=Int64 is not classified\n",
      "audio_valence of type=Float64 is not classified\n",
      "No of columns classified 0 does not match 13 total cols. Continuing...\n",
      "    Error: some columns missing from classification are: ['song_duration_ms', 'acousticness', 'danceability', 'energy', 'instrumentalness', 'key', 'liveness', 'loudness', 'audio_mode', 'speechiness', 'tempo', 'time_signature', 'audio_valence']\n",
      "        No variables were removed since no ID or low-information variables found in data set\n",
      "No GPU active on this device\n",
      "    Tuning XGBoost using CPU hyper-parameters. This will take time...\n",
      "    After removing redundant variables from further processing, features left = 13\n",
      "No interactions created for categorical vars since feature engg does not specify it\n",
      "#######################################################################################\n",
      "#####  Searching for Uncorrelated List Of Variables (SULOV) in 13 features ############\n",
      "#######################################################################################\n",
      "    there are no null values in dataset...\n",
      "    SelectKBest() function is erroring. Returning with all 13 variables...\n",
      "Time taken for SULOV method = 0 seconds\n",
      "    Adding 0 categorical variables to reduced numeric variables  of 13\n",
      "Final list of selected 13 vars after SULOV = ['acousticness', 'audio_mode', 'audio_valence', 'danceability', 'energy', 'instrumentalness', 'key', 'liveness', 'loudness', 'song_duration_ms', 'speechiness', 'tempo', 'time_signature']\n",
      "Converting all features to numeric before sending to XGBoost...\n",
      "#######################################################################################\n",
      "#####    R E C U R S I V E   X G B O O S T : F E A T U R E   S E L E C T I O N  #######\n",
      "#######################################################################################\n",
      "    using regular XGBoost\n",
      "Current number of predictors before recursive XGBoost = 13 \n",
      "    Taking top 3 features per iteration...\n",
      "    XGBoost version using 1.7.1 as tree method: hist\n",
      "Number of booster rounds = 100\n",
      "        using 13 variables...\n",
      "            selecting 6 features in this iteration\n",
      "            Time taken for regular XGBoost feature selection = 20 seconds\n",
      "        using 10 variables...\n",
      "            selecting 5 features in this iteration\n",
      "            Time taken for regular XGBoost feature selection = 19 seconds\n",
      "        using 7 variables...\n",
      "            selecting 3 features in this iteration\n",
      "            Time taken for regular XGBoost feature selection = 17 seconds\n",
      "        using 4 variables...\n",
      "            selecting 2 features in this iteration\n",
      "            Time taken for regular XGBoost feature selection = 15 seconds\n",
      "    Completed XGBoost feature selection in 0 seconds\n",
      "#######################################################################################\n",
      "#####          F E A T U R E   S E L E C T I O N   C O M P L E T E D            #######\n",
      "#######################################################################################\n",
      "Selected 8 important features:\n",
      "['danceability', 'loudness', 'liveness', 'acousticness', 'speechiness', 'time_signature', 'song_duration_ms', 'tempo']\n",
      "Total Time taken for featurewiz selection = 73 seconds\n",
      "Output contains a list of 8 important features and a train dataframe\n"
     ]
    }
   ],
   "source": [
    "df_f = df.drop([\"song_id\", \"song_name\"], axis=1)\n",
    "features = featurewiz(df_f, target=\"song_popularity\", corr_limit=0.70, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos la columna id\n",
    "X = df.drop(columns=[\"song_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"song_popularity\"\n",
    "X = df.drop(columns=[target])\n",
    "y = df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_engineering_pipeline(data, numeric_col_missing_threshold=0., exclude_cols=None):\n",
    "    \"\"\"Returns a dataframe with the data engineering pipeline applied.\n",
    "    This pipeline will:\n",
    "        - Convert 'category' columns to 'str' columns.\n",
    "        - Create a new column \"n_missing_values\" with the number of missing values per row.\n",
    "        - Convert missing values in 'str' columns to 'missing' string.\n",
    "        - Adds columns indicating if the value was missing or not for the numeric columns.\n",
    "    Args:\n",
    "        data (pandas.DataFrame): The dataframe to be analyzed.\n",
    "        numeric_col_missing_threshold (float): The threshold (percentage) for numeric columns to add a missing indicator.\n",
    "        exclude_cols (list): The columns to be excluded from the pipeline.\n",
    "    \"\"\"\n",
    "    exclude_cols = exclude_cols if exclude_cols is not None else []\n",
    "    data = data.copy()\n",
    "    data_subset = data.drop(exclude_cols, axis=1)\n",
    "\n",
    "    # Para evitar erores convertimos las columnas categóricas a string\n",
    "    data_subset = data_subset.copy().apply(lambda x: x.astype(\"str\") if x.dtype == \"category\" else x)\n",
    "\n",
    "    categorical_cols = data_subset.select_dtypes(include=[\"string\", \"object\"]).columns\n",
    "    numeric_cols = data_subset.select_dtypes(exclude=[\"string\", \"object\", \"datetime\"]).columns\n",
    "\n",
    "    # Creamos una nueva columna con el número de valores nulos por fila\n",
    "    data_subset[\"n_missing_values\"] = data_subset.isnull().sum(axis=1)\n",
    "\n",
    "    # Creamos una categoría \"missing\" para los valores faltantes\n",
    "    data_subset[categorical_cols] = data_subset[categorical_cols].fillna(\"missing\")\n",
    "\n",
    "    # Añadimos una columna por cada columna categórica que indique la frecuencia de cada valor en la columna\n",
    "    for col in categorical_cols:\n",
    "        data_subset[f\"{col}_freq\"] = data_subset[col].map(data_subset[col].value_counts(normalize=True))\n",
    "\n",
    "    # Añadimos una columna binaria por cada columna numérica que indique si el valor es nulo o no\n",
    "    for col in data_subset.select_dtypes(include=\"number\").columns:\n",
    "        if data_subset[col].isnull().mean() > numeric_col_missing_threshold:\n",
    "            data_subset[f\"{col}_isnull\"] = data_subset[col].isnull().astype(int)\n",
    "    \n",
    "    data = data[exclude_cols].merge(data_subset, how=\"left\", left_index=True, right_index=True)\n",
    "    \n",
    "    return data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "               song_name  song_id  song_duration_ms  acousticness  \\\n0  Maneater - Radio Edit     2231            270946        0.0153   \n1       Better Off Alone    18680            192835        0.0155   \n2      Song That I Heard    16908            237666         0.773   \n3                  Zumba    10155            263973       0.00205   \n4       Bumper To Bumper    18150            225933         0.148   \n\n   danceability  energy  instrumentalness  key  liveness  loudness  \\\n0         0.728   0.518          0.000042   11     0.103   -11.114   \n1         0.903   0.498          0.000008    8     0.105    -6.379   \n2         0.267   0.356           0.00176    8     0.167   -12.103   \n3         0.729   0.894             0.021    5     0.128    -3.494   \n4         0.771   0.735               0.0    5     0.288    -9.162   \n\n   audio_mode  speechiness    tempo  time_signature  audio_valence  \\\n0           0        0.038   88.708               4          0.833   \n1           1        0.108  121.974               4          0.439   \n2           1       0.0317   92.272               4          0.314   \n3           1       0.0397  124.992               4          0.832   \n4           0        0.116  119.983               4          0.385   \n\n   n_missing_values  \n0                 0  \n1                 0  \n2                 0  \n3                 0  \n4                 0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>song_name</th>\n      <th>song_id</th>\n      <th>song_duration_ms</th>\n      <th>acousticness</th>\n      <th>danceability</th>\n      <th>energy</th>\n      <th>instrumentalness</th>\n      <th>key</th>\n      <th>liveness</th>\n      <th>loudness</th>\n      <th>audio_mode</th>\n      <th>speechiness</th>\n      <th>tempo</th>\n      <th>time_signature</th>\n      <th>audio_valence</th>\n      <th>n_missing_values</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Maneater - Radio Edit</td>\n      <td>2231</td>\n      <td>270946</td>\n      <td>0.0153</td>\n      <td>0.728</td>\n      <td>0.518</td>\n      <td>0.000042</td>\n      <td>11</td>\n      <td>0.103</td>\n      <td>-11.114</td>\n      <td>0</td>\n      <td>0.038</td>\n      <td>88.708</td>\n      <td>4</td>\n      <td>0.833</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Better Off Alone</td>\n      <td>18680</td>\n      <td>192835</td>\n      <td>0.0155</td>\n      <td>0.903</td>\n      <td>0.498</td>\n      <td>0.000008</td>\n      <td>8</td>\n      <td>0.105</td>\n      <td>-6.379</td>\n      <td>1</td>\n      <td>0.108</td>\n      <td>121.974</td>\n      <td>4</td>\n      <td>0.439</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Song That I Heard</td>\n      <td>16908</td>\n      <td>237666</td>\n      <td>0.773</td>\n      <td>0.267</td>\n      <td>0.356</td>\n      <td>0.00176</td>\n      <td>8</td>\n      <td>0.167</td>\n      <td>-12.103</td>\n      <td>1</td>\n      <td>0.0317</td>\n      <td>92.272</td>\n      <td>4</td>\n      <td>0.314</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Zumba</td>\n      <td>10155</td>\n      <td>263973</td>\n      <td>0.00205</td>\n      <td>0.729</td>\n      <td>0.894</td>\n      <td>0.021</td>\n      <td>5</td>\n      <td>0.128</td>\n      <td>-3.494</td>\n      <td>1</td>\n      <td>0.0397</td>\n      <td>124.992</td>\n      <td>4</td>\n      <td>0.832</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Bumper To Bumper</td>\n      <td>18150</td>\n      <td>225933</td>\n      <td>0.148</td>\n      <td>0.771</td>\n      <td>0.735</td>\n      <td>0.0</td>\n      <td>5</td>\n      <td>0.288</td>\n      <td>-9.162</td>\n      <td>0</td>\n      <td>0.116</td>\n      <td>119.983</td>\n      <td>4</td>\n      <td>0.385</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_1 = data_engineering_pipeline(X, exclude_cols=[\"song_name\"])\n",
    "X_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = X_1.select_dtypes(include=[\"category\", \"string\", \"object\"]).columns\n",
    "num_cols = X_1.select_dtypes(exclude=[\"category\", \"string\", \"object\"]).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformación a variables numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = pipeline.Pipeline(steps=[\n",
    "    (\"imputer\", impute.SimpleImputer(strategy=\"mean\")),\n",
    "    (\"scaler\", preprocessing.StandardScaler())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformación en las variables categóticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_transformer = pipeline.Pipeline(steps=[\n",
    "    (\"imputer\", impute.SimpleImputer(strategy=\"constant\", fill_value=\"missing\")),\n",
    "    (\"onehot\", preprocessing.OneHotEncoder(handle_unknown=\"infrequent_if_exist\", \n",
    "                                           sparse=False,\n",
    "                                           min_frequency=0.05))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicamos las transformaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = compose.ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, num_cols),\n",
    "        (\"cat\", categorical_transformer, cat_cols)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "    song_id  song_duration_ms  acousticness  danceability    energy  \\\n0 -1.316695          0.872819     -0.843162      0.604600 -0.596246   \n1  1.705451         -0.427460     -0.842469      1.727602 -0.689664   \n2  1.379885          0.318821      1.782357     -2.353706 -1.352937   \n3  0.139168          0.756742     -0.889075      0.611017  1.160025   \n4  1.608075          0.123507     -0.383341      0.880538  0.417347   \n\n   instrumentalness       key  liveness  loudness  audio_mode  speechiness  \\\n0         -0.349384  1.587400 -0.527658 -0.954294   -1.299813    -0.607703   \n1         -0.349538  0.757736 -0.513736  0.277339    0.769341     0.065332   \n2         -0.341590  0.757736 -0.082150 -1.211545    0.769341    -0.668277   \n3         -0.254314 -0.071929 -0.353632  1.027764    0.769341    -0.591358   \n4         -0.349574 -0.071929  0.760138 -0.446554   -1.299813     0.142250   \n\n      tempo  time_signature  audio_valence  n_missing_values  \\\n0 -1.126897        0.132607       1.236175               0.0   \n1  0.033705        0.132607      -0.362894               0.0   \n2 -1.002554        0.132607      -0.870213               0.0   \n3  0.138999        0.132607       1.232117               0.0   \n4 -0.035758        0.132607      -0.582056               0.0   \n\n   song_name_infrequent_sklearn  \n0                           1.0  \n1                           1.0  \n2                           1.0  \n3                           1.0  \n4                           1.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>song_id</th>\n      <th>song_duration_ms</th>\n      <th>acousticness</th>\n      <th>danceability</th>\n      <th>energy</th>\n      <th>instrumentalness</th>\n      <th>key</th>\n      <th>liveness</th>\n      <th>loudness</th>\n      <th>audio_mode</th>\n      <th>speechiness</th>\n      <th>tempo</th>\n      <th>time_signature</th>\n      <th>audio_valence</th>\n      <th>n_missing_values</th>\n      <th>song_name_infrequent_sklearn</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-1.316695</td>\n      <td>0.872819</td>\n      <td>-0.843162</td>\n      <td>0.604600</td>\n      <td>-0.596246</td>\n      <td>-0.349384</td>\n      <td>1.587400</td>\n      <td>-0.527658</td>\n      <td>-0.954294</td>\n      <td>-1.299813</td>\n      <td>-0.607703</td>\n      <td>-1.126897</td>\n      <td>0.132607</td>\n      <td>1.236175</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.705451</td>\n      <td>-0.427460</td>\n      <td>-0.842469</td>\n      <td>1.727602</td>\n      <td>-0.689664</td>\n      <td>-0.349538</td>\n      <td>0.757736</td>\n      <td>-0.513736</td>\n      <td>0.277339</td>\n      <td>0.769341</td>\n      <td>0.065332</td>\n      <td>0.033705</td>\n      <td>0.132607</td>\n      <td>-0.362894</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.379885</td>\n      <td>0.318821</td>\n      <td>1.782357</td>\n      <td>-2.353706</td>\n      <td>-1.352937</td>\n      <td>-0.341590</td>\n      <td>0.757736</td>\n      <td>-0.082150</td>\n      <td>-1.211545</td>\n      <td>0.769341</td>\n      <td>-0.668277</td>\n      <td>-1.002554</td>\n      <td>0.132607</td>\n      <td>-0.870213</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.139168</td>\n      <td>0.756742</td>\n      <td>-0.889075</td>\n      <td>0.611017</td>\n      <td>1.160025</td>\n      <td>-0.254314</td>\n      <td>-0.071929</td>\n      <td>-0.353632</td>\n      <td>1.027764</td>\n      <td>0.769341</td>\n      <td>-0.591358</td>\n      <td>0.138999</td>\n      <td>0.132607</td>\n      <td>1.232117</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.608075</td>\n      <td>0.123507</td>\n      <td>-0.383341</td>\n      <td>0.880538</td>\n      <td>0.417347</td>\n      <td>-0.349574</td>\n      <td>-0.071929</td>\n      <td>0.760138</td>\n      <td>-0.446554</td>\n      <td>-1.299813</td>\n      <td>0.142250</td>\n      <td>-0.035758</td>\n      <td>0.132607</td>\n      <td>-0.582056</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_2 = preprocessor.fit_transform(X_1)\n",
    "column_names = preprocessor.named_transformers_[\"cat\"][\"onehot\"].get_feature_names(cat_cols)\n",
    "column_names = num_cols.tolist() + column_names.tolist()\n",
    "X_2 = pd.DataFrame(data=X_2, columns=column_names)\n",
    "X_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selección de características"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para realizar la selección de características vamos a utilizar varios métodos, por lo que llevaremos un recuento de cuántas veces una variable ha sido propuesta para ser eliminada por cada uno de ellos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "elimination_recount = {col: 0 for col in X_2.columns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_recount(cols):\n",
    "    for col in cols:\n",
    "        elimination_recount[col] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Métodos de filtro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Valores nulos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este dataset no presenta valores nulos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Columnas casi constantes o con varianza demasiado baja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_constant_cols(df_: pd.DataFrame, \n",
    "                      constant_threshold: float = 0.95, \n",
    "                      variance_threshold: float = 0.1, \n",
    "                      verbose: bool = True) -> pd.DataFrame:\n",
    "    \"\"\"Returns a dict of quasi-constant columns and the percentage of the most frequent value\n",
    "    from a dataframe.\n",
    "    Args:\n",
    "        df_ (pandas.DataFrame): The dataframe to be analyzed.\n",
    "        constant_threshold (float): The threshold for quasi-constant columns.\n",
    "        variance_threshold (float): The threshold for low variance columns.\n",
    "        verbose (bool): Whether to print the message with detail information about the reason of the deletion.\n",
    "    :returns pandas.DataFrame\n",
    "    \"\"\"\n",
    "    cols = []\n",
    "    del_cols_constant = []\n",
    "    for column in df_.columns:\n",
    "        try:\n",
    "            percentage = df_[column].value_counts(normalize=True).values[0]\n",
    "        except IndexError:\n",
    "            percentage = 0\n",
    "        if percentage < constant_threshold:\n",
    "            cols.append(column)\n",
    "        else:\n",
    "            del_cols_constant.append(column)\n",
    "    df_new = df_[cols]\n",
    "    num_df_ = df_new.select_dtypes(exclude=['object', 'category', 'string'])\n",
    "    selector = feature_selection.VarianceThreshold(variance_threshold)\n",
    "    selector.fit(num_df_)\n",
    "    cat_cols = df_new.select_dtypes(include=['object', 'category', 'string']).columns\n",
    "    num_cols = num_df_.columns[selector.get_support(indices=True)]\n",
    "    all_cols = cat_cols.union(num_cols)\n",
    "    cols_num = sorted(df_.columns.get_indexer(all_cols))\n",
    "    if verbose:\n",
    "        print(f'Columns deleted because of constant values: {del_cols_constant}')\n",
    "        print(f'Columns deleted because of VarianceThreshold: {[col for col in num_df_.columns if col not in num_cols]}')\n",
    "    return del_cols_constant + [col for col in num_df_.columns if col not in num_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns deleted because of constant values: ['time_signature', 'n_missing_values', 'song_name_infrequent_sklearn']\n",
      "Columns deleted because of VarianceThreshold: []\n"
     ]
    }
   ],
   "source": [
    "constant_cols = del_constant_cols(X_2, constant_threshold=0.9, variance_threshold=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_3 = X_2.drop(constant_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "song_id             float64\nsong_duration_ms    float64\nacousticness        float64\ndanceability        float64\nenergy              float64\ninstrumentalness    float64\nkey                 float64\nliveness            float64\nloudness            float64\naudio_mode          float64\nspeechiness         float64\ntempo               float64\naudio_valence       float64\ndtype: object"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_3.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Selección de K mejores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['song_id', 'song_duration_ms', 'acousticness', 'danceability',\n       'instrumentalness', 'liveness', 'loudness', 'speechiness', 'tempo',\n       'audio_valence'],\n      dtype='object')"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Usamos sklearn para quedarnos con las K mejores columnas (SelectKBest)\n",
    "percentage_of_colums_to_keep = 0.8\n",
    "k = int(len(X_3.columns) * percentage_of_colums_to_keep)\n",
    "score_func = feature_selection.f_regression\n",
    "selector = feature_selection.SelectKBest(score_func=score_func, k=k)\n",
    "X_3 = X_3.astype(float)\n",
    "y = y.astype(float)\n",
    "selector.fit(X_3, y)\n",
    "cols = selector.get_support(indices=True)\n",
    "cols = X_3.columns[cols]\n",
    "cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Métodos de Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Métodos de embeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are going to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c58f7bc89ae2062a854a2fabf05300abbc8a4cce216c1c46d98684f673bde574"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
